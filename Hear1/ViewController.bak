import AVFoundation
import SwiftUI
import UIKit
import Speech


class ViewController: UIViewController, AVAudioRecorderDelegate {
    // 引入 AVFoundation 库，声明 ViewController 类并继承自 UIViewController 和 AVAudioRecorderDelegate 类
    
    var audioSession: AVAudioSession!
    var audioRecorder: AVAudioRecorder!
    // 声明两个实例变量，audioSession 和 audioRecorder，用于配置和录制音频
    
    var body: some View {
        Text("Hello, world!")
            .padding()
    }
    
    //这前面鼠标移动到这个圆圈有个+号，然后点击+号不放，会出现箭头，把箭头指向按钮，就可以绑定事件了
    @IBAction func addNewWord(sender:UIButton){
        print("点击成功")
        let fileManager = FileManager.default
        let documentsPath = fileManager.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let recordingsPath = documentsPath.appendingPathComponent("recordings")
        do{
          try   fileManager.createDirectory(at: recordingsPath, withIntermediateDirectories: true, attributes: nil)
        }catch {
            print("错误00")
            print("Error creating directory or starting recording: \(error.localizedDescription)")
        }
        

        // Create a file URL for the new recording with the current date and time as the file name
        let currentDateTime = Date()
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd-HH-mm-ss"
        let recordingName = formatter.string(from: currentDateTime) + ".wav"
        let recordingURL = recordingsPath.appendingPathComponent(recordingName)

        do {
            // Create a directory for recordings
            
            var audioRecorder: AVAudioRecorder?

            // Start recording to the new file URL
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
            try audioSession.setActive(true)
            let audioSettings = [AVFormatIDKey: Int(kAudioFormatLinearPCM),
                                 AVSampleRateKey: 44100,
                                 AVNumberOfChannelsKey: 2,
                                 AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue]
            audioRecorder = try AVAudioRecorder(url: recordingURL, settings: audioSettings)
            //测试是否可以开始录音
            audioRecorder?.prepareToRecord()

            audioRecorder?.record()
            // Record for 5 seconds
            DispatchQueue.main.asyncAfter(deadline: .now() + 10.0) {
                audioRecorder?.stop()
                print("录制完成")
            }
        } catch {
            print("错误11")
            print("Error creating directory or starting recording: \(error.localizedDescription)")
        }

        Thread.sleep(forTimeInterval: 15.0) // 休眠10秒钟

        // 2. 使用语音识别API将录制的音频转换为文字
        
        let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh_CN"))
            let request = try SFSpeechURLRecognitionRequest(url: recordingURL)
            recognizer?.recognitionTask(with: request) { (result, error) in
                
                      guard let result = result else {
                        print("错误22")
                        print(error ?? "语音识别错误")
                        return
                    }
                    print(result.bestTranscription.formattedString)
                    
                    // 3. 将文字转换为语音输出到AirPods
                    let openaiResponse = "你好，我是你的机器人"// 调用OpenAI API，获取响应
                    let synthesizer = AVSpeechSynthesizer()
                    let utterance = AVSpeechUtterance(string: openaiResponse)
                    utterance.voice = AVSpeechSynthesisVoice(identifier: "com.apple.ttsbundle.Samantha-compact")
                    synthesizer.speak(utterance)
                }
                
           
        
        

    }
    
  
    
    override func viewDidLoad() {
        print("你终于到了")
        super.viewDidLoad()
        // 在视图加载时执行父类的 viewDidLoad 方法
//        
//        audioSession = AVAudioSession.sharedInstance()
//        // 获取音频会话的共享实例
//        
//        do {
//            try audioSession.setCategory(.playAndRecord, mode: .default)
//            try audioSession.setActive(true)
//            // 配置音频会话为同时录制和播放，并激活音频会话
//        } catch {
//            print("Error configuring audio session")
//            // 输出错误信息
//        }
//        
//        let audioURL = getDocumentsDirectory().appendingPathComponent("recording.wav")
//        // 获取应用程序的 Documents 目录，并在其下创建名为 "recording.wav" 的音频文件
//        
//        let audioSettings: [String:Any] = [AVFormatIDKey: Int(kAudioFormatLinearPCM),
//                                         AVSampleRateKey: 44100.0,
//                                   AVNumberOfChannelsKey: 2,
//                                  AVLinearPCMBitDepthKey: 16,
//                               AVLinearPCMIsBigEndianKey: false,
//                                   AVLinearPCMIsFloatKey: false]
//        // 配置音频文件格式、采样率、通道数和比特深度等设置
//        
//        do {
//            audioRecorder = try AVAudioRecorder(url: audioURL, settings: audioSettings)
//            audioRecorder.delegate = self
//            audioRecorder.record()
//            // 根据指定的音频 URL 和设置创建音频录制器，将其委托设置为 ViewController，开始录制音频
//        } catch {
//            print("Error creating audio recorder")
//            // 输出错误信息
//        }
        
    }
    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        let documentsDirectory = paths[0]
        return documentsDirectory
        // 返回应用程序的 Documents 目录
    }
    
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        if flag {
            print("Audio recording was successful")
            // 输出成功录制音频的信息
        } else {
            print("Audio recording failed")
            // 输出录制音频失败的信息
        }
    }
    
    
   
}




